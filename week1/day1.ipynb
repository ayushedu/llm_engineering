{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# YOUR FIRST LAB\n",
    "### Please read this section. This is valuable to get you prepared, even if it's a long read -- it's important stuff.\n",
    "\n",
    "### Also, be sure to read [README.md](../README.md)! More info about the updated videos in the README and [top of the course resources in purple](https://edwarddonner.com/2024/11/13/llm-engineering-resources/)\n",
    "\n",
    "## Your first Frontier LLM Project\n",
    "\n",
    "By the end of this course, you will have built an autonomous Agentic AI solution with 7 agents that collaborate to solve a business problem. All in good time! We will start with something smaller...\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, you should have completed the setup linked in the README.\n",
    "\n",
    "### If you're new to working in \"Notebooks\" (also known as Labs or Jupyter Lab)\n",
    "\n",
    "Welcome to the wonderful world of Data Science experimentation! Simply click in each \"cell\" with code in it, such as the cell immediately below this text, and hit Shift+Return to execute that cell. Be sure to run every cell, starting at the top, in order.\n",
    "\n",
    "Please look in the [Guides folder](../guides/01_intro.ipynb) for all the guides.\n",
    "\n",
    "## I am here to help\n",
    "\n",
    "If you have any problems at all, please do reach out.  \n",
    "I'm available through the platform, or at ed@edwarddonner.com, or at https://www.linkedin.com/in/eddonner/ if you'd like to connect (and I love connecting!)  \n",
    "And this is new to me, but I'm also trying out X at [@edwarddonner](https://x.com/edwarddonner) - if you're on X, please show me how it's done ðŸ˜‚  \n",
    "\n",
    "## More troubleshooting\n",
    "\n",
    "Please see the [troubleshooting](../setup/troubleshooting.ipynb) notebook in the setup folder to diagnose and fix common problems. At the very end of it is a diagnostics script with some useful debug info.\n",
    "\n",
    "## If this is old hat!\n",
    "\n",
    "If you're already comfortable with today's material, please hang in there; you can move swiftly through the first few labs - we will get much more in depth as the weeks progress. Ultimately we will fine-tune our own LLM to compete with OpenAI!\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Please read - important note</h2>\n",
    "            <span style=\"color:#900;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations. If you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">This code is a live resource - keep an eye out for my emails</h2>\n",
    "            <span style=\"color:#f71;\">I push updates to the code regularly. As people ask questions, I add more examples or improved commentary. As a result, you'll notice that the code below isn't identical to the videos. Everything from the videos is here; but I've also added better explanations and new models like DeepSeek. Consider this like an interactive book.<br/><br/>\n",
    "                I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business value of these exercises</h2>\n",
    "            <span style=\"color:#181;\">A final thought. While I've designed these notebooks to be educational, I've also tried to make them enjoyable. We'll do fun things like have LLMs tell jokes and argue with each other. But fundamentally, my goal is to teach skills you can apply in business. I'll explain business implications as we go, and it's worth keeping this in mind: as you build experience with models and techniques, think of ways you could put this into action at work today. Please do contact me if you'd like to discuss more or if you have ideas to bounce off me.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f28feb",
   "metadata": {},
   "source": [
    "### If necessary, install Cursor Extensions\n",
    "\n",
    "1. From the View menu, select Extensions\n",
    "2. Search for Python\n",
    "3. Click on \"Python\" made by \"ms-python\" and select Install if not already installed\n",
    "4. Search for Jupyter\n",
    "5. Click on \"Jupyter\" made by \"ms-toolsai\" and select Install if not already installed\n",
    "\n",
    "\n",
    "### Next Select the Kernel\n",
    "\n",
    "Click on \"Select Kernel\" on the Top Right\n",
    "\n",
    "Choose \"Python Environments...\"\n",
    "\n",
    "Then choose the one that looks like `.venv (Python 3.12.x) .venv/bin/python` - it should be marked as \"Recommended\" and have a big star next to it.\n",
    "\n",
    "Any problems with this? Head over to the troubleshooting.\n",
    "\n",
    "### Note: you'll need to set the Kernel with every notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from scraper import fetch_website_contents\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "# If you get an error running this cell, then please head over to the troubleshooting notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900b2a8-6384-4316-8aaa-5e519fca4254",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI (or Ollama)\n",
    "\n",
    "The next cell is where we load in the environment variables in your `.env` file and connect to OpenAI.  \n",
    "\n",
    "If you'd like to use free Ollama instead, please see the README section \"Free Alternative to Paid APIs\", and if you're not sure how to do this, there's a full solution in the solutions folder (day1_with_ollama.ipynb).\n",
    "\n",
    "## Troubleshooting if you have problems:\n",
    "\n",
    "If you get a \"Name Error\" - have you run all cells from the top down? Head over to the Python Foundations guide for a bulletproof way to find and fix all Name Errors.\n",
    "\n",
    "If that doesn't fix it, head over to the [troubleshooting](../setup/troubleshooting.ipynb) notebook for step by step code to identify the root cause and fix it!\n",
    "\n",
    "Or, contact me! Message me or email ed@edwarddonner.com and we will get this to work.\n",
    "\n",
    "Any concerns about API costs? See my notes in the README - costs should be minimal, and you can control it at every point. You can also use Ollama as a free alternative, which we discuss during Day 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCU6rsxe5tkwd2LHVBsfLJWA4kTKY8Ki3k\n",
      "An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "print(api_key)\n",
    "# Check the key\n",
    "\n",
    "if not api_key:\n",
    "    print(\"No API key was found - please head over to the troubleshooting notebook in this folder to identify & fix!\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key - see troubleshooting notebook\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - see troubleshooting notebook\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc84b-0815-4f40-99ab-d9a5da6bda91",
   "metadata": {},
   "source": [
    "# Let's make a quick call to a Frontier model to get started, as a preview!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a58394bf-1e45-46af-9bfd-01e24da6f49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Hello, GPT! This is my first ever message to you! Hi!'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To give you a preview -- calling OpenAI with these messages is this easy. Any problems, head over to the Troubleshooting notebook.\n",
    "\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08330159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello there! It's fantastic to meet you! A very warm welcome to our first conversation.\\n\\nHow can I help you today? Or, if you're just exploring, feel free to ask me anything at all! ðŸ˜Š\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
    "openai = OpenAI(base_url=GEMINI_BASE_URL, api_key=api_key)\n",
    "\n",
    "response = openai.chat.completions.create(model=GEMINI_MODEL, messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa190e5-cb31-456a-96cc-db109919cd78",
   "metadata": {},
   "source": [
    "## OK onwards with our first project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "Iâ€™m Ed. I like writing code and experimenting with LLMs, and hopefully youâ€™re here because you do too. I also enjoy DJing (but Iâ€™m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "Iâ€™m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". Weâ€™re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. Iâ€™m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, weâ€™ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "November 11, 2025\n",
      "The Unique Energy of an AI Live Event\n",
      "September 15, 2025\n",
      "AI Engineering MLOps Track â€“ Deploy AI to Production\n",
      "May 28, 2025\n",
      "The AI Curriculum\n",
      "May 18, 2025\n",
      "AI Leadership Track â€“ Gen AI and Agentic AI for Business Leaders\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your emailâ€¦\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try out this utility\n",
    "\n",
    "ed = fetch_website_contents(\"https://edwarddonner.com\")\n",
    "print(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "You may know this already - but if not, you will get very familiar with it!\n",
    "\n",
    "Models like GPT have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a snarky assistant that analyzes the contents of a website,\n",
    "and provides a short, snarky, humorous summary, ignoring text that might be navigation related.\n",
    "Respond in markdown. Do not wrap the markdown in a code block - respond just with the markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0275b1b-7cfe-4f9d-abfa-7650d378da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user prompt\n",
    "\n",
    "user_prompt_prefix = \"\"\"\n",
    "Here are the contents of a website.\n",
    "Provide a short summary of this website.\n",
    "If it includes news or announcements, then summarize these too.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea211b5f-28e1-4a86-8e52-c0b7677cadcc",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f25dcd35-0cd0-4235-9f64-ac37ed9eaaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 + 2 = 4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2 + 2?\"}\n",
    "]\n",
    "\n",
    "GEMINI_MODEL = \"gemini-2.5-flash\"\n",
    "response = openai.chat.completions.create(model=GEMINI_MODEL, messages=messages)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
   "metadata": {},
   "source": [
    "## And now let's build useful messages for GPT-4.1-mini, using a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_prefix + website}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36478464-39ee-485c-9f3f-6a4e458dbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out, and then try for a few more websites\n",
    "\n",
    "messages_for(ed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
   "metadata": {},
   "source": [
    "## Time to bring it together - the API for OpenAI is very simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = fetch_website_contents(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = GEMINI_MODEL,\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e38d41-dfa4-4b20-9c96-c46ea75d9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3018853a-445f-41ff-9560-d925d1774b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bcf6f4-adce-45e9-97ad-d9a5d7a3a624",
   "metadata": {},
   "source": [
    "# Let's try more websites\n",
    "\n",
    "Note that this will only work on websites that can be scraped using this simplistic approach.\n",
    "\n",
    "Websites that are rendered with Javascript, like React apps, won't show up. See the community-contributions folder for a Selenium implementation that gets around this. You'll need to read up on installing Selenium (ask ChatGPT!)\n",
    "\n",
    "Also Websites protected with CloudFront (and similar) may give 403 errors - many thanks Andy J for pointing this out.\n",
    "\n",
    "But many websites will work just fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d83403-a24c-44b5-84ac-961449b4008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9fd40-b354-4341-991e-863ef2e59db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951be1a-7f1b-448f-af1f-845978e47e2c",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business applications</h2>\n",
    "            <span style=\"color:#181;\">In this exercise, you experienced calling the Cloud API of a Frontier Model (a leading model at the frontier of AI) for the first time. We will be using APIs like OpenAI at many stages in the course, in addition to building our own LLMs.\n",
    "\n",
    "More specifically, we've applied this to Summarization - a classic Gen AI use case to make a summary. This can be applied to any business vertical - summarizing the news, summarizing financial performance, summarizing a resume in a cover letter - the applications are limitless. Consider how you could apply Summarization in your business, and try prototyping a solution.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue - now try yourself</h2>\n",
    "            <span style=\"color:#900;\">Use the cell below to make your own simple commercial example. Stick with the summarization use case for now. Here's an idea: write something that will take the contents of an email, and will suggest an appropriate short subject line for the email. That's the kind of feature that might be built into a commercial email tool.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00743dac-0e70-45b7-879a-d7293a6f68a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an excellent goal for a Senior Engineer! Your background in Scala and Java, particularly if it involved distributed systems, data processing (e.g., Spark), or high-performance backends, provides a fantastic foundation for tackling the complexities of LLM and ML development.\n",
      "\n",
      "The key is to leverage your existing software engineering maturity while acquiring new domain-specific knowledge and tools.\n",
      "\n",
      "Here's a comprehensive plan, broken down into phases:\n",
      "\n",
      "---\n",
      "\n",
      "## Plan for a Senior Engineer: Scala/Java to LLM/ML Development\n",
      "\n",
      "**Goal:** Transition into a role focused on LLM and Machine Learning development, leveraging existing Senior Software Engineering skills.\n",
      "\n",
      "**Target Roles:** ML Engineer, Applied Scientist (ML), MLOps Engineer, AI Platform Engineer.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 0: Self-Assessment & Mindset (Weeks 1-2)\n",
      "\n",
      "1.  **Identify Current Strengths:**\n",
      "    *   **Software Engineering:** Architecture, design patterns, testing, CI/CD, code quality, performance optimization, debugging, distributed systems, concurrency. These are *highly* transferable.\n",
      "    *   **Data Engineering (if applicable):** If you've worked with data pipelines, Kafka, Spark, data warehousing, this is a huge advantage for ML data preparation and feature engineering.\n",
      "    *   **Problem Solving:** Your senior experience means you can break down complex problems.\n",
      "    *   **Project Management/Leadership:** Ability to lead projects, mentor, and communicate.\n",
      "\n",
      "2.  **Identify Key Gaps:**\n",
      "    *   **Core ML Concepts:** Supervised/Unsupervised Learning, Regression, Classification, Model Evaluation, Feature Engineering, Overfitting, etc.\n",
      "    *   **Deep Learning Fundamentals:** Neural Networks, CNNs, RNNs, Transformers.\n",
      "    *   **LLM Specifics:** Prompt Engineering, RAG (Retrieval Augmented Generation), Fine-tuning, Vector Databases, specific LLM architectures.\n",
      "    *   **Python Ecosystem:** Data manipulation (Pandas, NumPy), ML frameworks (PyTorch/TensorFlow), specific ML/LLM libraries (Hugging Face).\n",
      "    *   **Basic Math & Stats:** Linear algebra, calculus (gradients), probability, statistics.\n",
      "    *   **MLOps:** Tools and practices for deploying, monitoring, and maintaining ML models in production.\n",
      "\n",
      "3.  **Set Realistic Expectations:** This is a significant shift. It will require dedicated study and practice. Expect at least 6-12 months of intensive learning and project work before feeling proficient in a new role.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 1: Foundational Learning & Tooling (Months 1-3)\n",
      "\n",
      "The goal here is to build a solid base in Python, essential math, and core ML concepts.\n",
      "\n",
      "1.  **Master Python & its Data Ecosystem:**\n",
      "    *   **Language Fundamentals:** Refresh or learn Python syntax, data structures, OOP.\n",
      "    *   **Essential Libraries:**\n",
      "        *   `NumPy`: Numerical computing.\n",
      "        *   `Pandas`: Data manipulation and analysis (this is *critical* for ML data prep).\n",
      "        *   `Matplotlib`/`Seaborn`: Data visualization.\n",
      "        *   `Scikit-learn`: Classic ML algorithms (start here for basic model understanding).\n",
      "    *   **Practice:** Solve Python challenges, re-implement some simple data structures or algorithms.\n",
      "\n",
      "2.  **Reinforce Essential Math & Statistics:**\n",
      "    *   **Linear Algebra:** Vectors, matrices, dot products, eigenvalues (understand the intuition behind these for neural networks).\n",
      "    *   **Calculus:** Derivatives, gradients (understand how they relate to optimization).\n",
      "    *   **Probability & Statistics:** Basic distributions, hypothesis testing, correlation, variance, bias (crucial for model evaluation and understanding data).\n",
      "    *   **Resources:** Khan Academy, 3Blue1Brown (videos are excellent for intuition), online courses specifically for ML math. *Focus on the intuition and application, not just rote memorization.*\n",
      "\n",
      "3.  **Grasp Core Machine Learning Concepts:**\n",
      "    *   **Key Concepts:** Supervised vs. Unsupervised, Regression vs. Classification, Bias-Variance Tradeoff, Overfitting/Underfitting, Cross-Validation, Feature Engineering, Evaluation Metrics (Accuracy, Precision, Recall, F1, ROC-AUC, RMSE, MAE).\n",
      "    *   **Basic Algorithms:** Linear Regression, Logistic Regression, Decision Trees, Random Forests, SVMs, K-Means.\n",
      "    *   **Resources:**\n",
      "        *   **Andrew Ng's Machine Learning Specialization (Coursera):** A classic and highly recommended starting point.\n",
      "        *   **\"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by AurÃ©lien GÃ©ron:** Excellent practical guide.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 2: Deep Dive into Deep Learning & LLMs (Months 4-7)\n",
      "\n",
      "Now, move into the more advanced topics and the specific LLM world.\n",
      "\n",
      "1.  **Deep Learning Fundamentals:**\n",
      "    *   **Neural Networks:** Perceptrons, activation functions, backpropagation (understand the intuition and process).\n",
      "    *   **Architectures:**\n",
      "        *   **CNNs:** Convolutional Neural Networks (for image tasks, good for understanding specialized layers).\n",
      "        *   **RNNs/LSTMs:** Recurrent Neural Networks (for sequence data, understand limitations).\n",
      "        *   **Transformers:** The *most critical* architecture for LLMs. Understand self-attention, multi-head attention, encoder-decoder structure.\n",
      "    *   **Frameworks:** Choose one to start â€“ **PyTorch is often preferred for research and flexibility**, TensorFlow is robust for production.\n",
      "        *   Learn how to build, train, and evaluate simple neural networks.\n",
      "    *   **Resources:**\n",
      "        *   **Deep Learning Specialization by Andrew Ng (Coursera):** Follow-up to his ML course.\n",
      "        *   **\"Deep Learning with Python\" by FranÃ§ois Chollet:** Practical guide using Keras/TensorFlow.\n",
      "        *   **fast.ai course:** Practical, top-down approach to deep learning.\n",
      "\n",
      "2.  **LLM Specifics:**\n",
      "    *   **Hugging Face Ecosystem:** This is the de-facto standard for LLMs. Learn to use:\n",
      "        *   `transformers` library: Load pre-trained models, tokenize, generate text.\n",
      "        *   `datasets` library: Load and prepare data for LLMs.\n",
      "        *   `accelerate` (for distributed training).\n",
      "    *   **Prompt Engineering:** Techniques for crafting effective prompts (few-shot, chain-of-thought, persona prompting).\n",
      "    *   **Vector Databases & Embeddings:** Understand what embeddings are, how to generate them (e.g., using `sentence-transformers`), and how to use vector databases (e.g., Pinecone, Weaviate, ChromaDB, FAISS) for RAG.\n",
      "    *   **Retrieval Augmented Generation (RAG):** The current standard for grounding LLMs with external knowledge. Understand the architecture: indexing, retrieval, generation.\n",
      "    *   **Fine-tuning:** Concepts of PEFT (Parameter Efficient Fine-Tuning) methods like LoRA. Understand when to fine-tune vs. prompt engineer.\n",
      "    *   **Evaluation Metrics:** BLEU, ROUGE, Perplexity for generative tasks. Understand human evaluation.\n",
      "    *   **Resources:**\n",
      "        *   **Hugging Face Course:** Excellent and practical.\n",
      "        *   **Online blogs, papers, and tutorials on RAG, fine-tuning.**\n",
      "        *   **LangChain/LlamaIndex:** Frameworks to build LLM applications.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 3: Practical Application & Portfolio Building (Months 7-10)\n",
      "\n",
      "This is where your senior engineering experience truly kicks in. Apply what you've learned to build projects.\n",
      "\n",
      "1.  **Kaggle Competitions:**\n",
      "    *   Start with beginner-friendly competitions.\n",
      "    *   Focus on understanding data, feature engineering, model selection, and evaluation.\n",
      "    *   Review winning solutions to learn best practices.\n",
      "\n",
      "2.  **Personal Projects (Crucial for demonstrating skills):**\n",
      "    *   **Small ML Projects:** Implement classic algorithms from scratch. Build a simple image classifier or text sentiment analyzer.\n",
      "    *   **LLM-Specific Project 1 (RAG):**\n",
      "        *   Build a Q&A chatbot over a set of your own documents (e.g., your blog posts, documentation).\n",
      "        *   Use `sentence-transformers` for embeddings, a local vector database (like ChromaDB), and a hosted LLM API (OpenAI, Anthropic) or a local open-source model.\n",
      "        *   **Focus on:** Data ingestion, chunking, embedding generation, retrieval accuracy, prompt design, and evaluating response quality.\n",
      "    *   **LLM-Specific Project 2 (Fine-tuning/Agent):**\n",
      "        *   Fine-tune a small open-source model (e.g., from Hugging Face) for a specific task (e.g., summarization of meeting notes, specific style of writing).\n",
      "        *   Or, build a multi-step LLM \"agent\" that can use tools to achieve a goal.\n",
      "    *   **Showcase on GitHub:**\n",
      "        *   Clean code, well-documented, clear `README.md` with instructions and results.\n",
      "        *   Include unit tests, CI/CD where appropriate (leveraging your existing skills!).\n",
      "\n",
      "3.  **Blog/Technical Writing:**\n",
      "    *   Write about your learning journey, specific challenges, or how you solved a problem in your projects. This demonstrates understanding and communication skills.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 4: MLOps & Productionization (Months 10-12+)\n",
      "\n",
      "This is where your existing Scala/Java software engineering maturity becomes a massive differentiator. You can build robust, scalable ML systems.\n",
      "\n",
      "1.  **Understand the MLOps Lifecycle:** Data preparation, model training, versioning, deployment, monitoring, re-training.\n",
      "2.  **Tools & Concepts:**\n",
      "    *   **Containerization:** `Docker` (essential for packaging ML applications).\n",
      "    *   **Orchestration:** `Kubernetes` (for deploying and scaling ML services).\n",
      "    *   **ML Metadata/Experiment Tracking:** `MLflow`, `Weights & Biases` (for tracking experiments, models, and parameters).\n",
      "    *   **Data Orchestration:** `Airflow`, `Prefect`, `Dagster` (for scheduling and managing data pipelines).\n",
      "    *   **Model Serving:** `FastAPI` (for building API endpoints for models), `BentoML`, `Seldon Core`, `Triton Inference Server`.\n",
      "    *   **Cloud ML Platforms:** AWS SageMaker, GCP Vertex AI, Azure ML (understand their offerings for training, deployment, and monitoring).\n",
      "    *   **Data Pipelines:** If you have Spark/Kafka experience, focus on how these integrate into ML data ingestion and feature store creation.\n",
      "    *   **Monitoring:** Model drift, data drift, performance metrics.\n",
      "3.  **Leverage your Scala/Java skills:**\n",
      "    *   **Data Engineering:** Your experience with Spark, Kafka, distributed databases is *highly valuable* for building scalable data ingestion and feature engineering pipelines for ML.\n",
      "    *   **Backend Services:** Build robust API gateways, orchestration layers, and data services in Java/Scala that interact with Python-based ML models.\n",
      "    *   **Infrastructure as Code:** Apply your IaC experience to ML infrastructure (Terraform, CloudFormation).\n",
      "    *   **Reliability & Performance:** Design ML systems with resilience, observability, and performance in mind â€“ areas you already excel at.\n",
      "4.  **Project:** Build an end-to-end ML/LLM application, from data ingestion to model deployment and monitoring. For example, deploy your RAG chatbot project as a FastAPI service inside Docker, potentially on Kubernetes.\n",
      "\n",
      "---\n",
      "\n",
      "### Phase 5: Career Transition & Interview Prep (Ongoing)\n",
      "\n",
      "1.  **Update Resume/LinkedIn:**\n",
      "    *   Reframe your experience to highlight transferable skills (distributed systems, data pipelines, software architecture, performance) *and* your new ML/LLM skills.\n",
      "    *   Showcase your projects prominently.\n",
      "2.  **Network:**\n",
      "    *   Connect with ML/LLM professionals on LinkedIn.\n",
      "    *   Attend virtual or local meetups, conferences, and webinars.\n",
      "    *   Informational interviews can provide valuable insights and leads.\n",
      "3.  **Interview Preparation:**\n",
      "    *   **Coding:** Practice Python data structures and algorithms (LeetCode).\n",
      "    *   **ML Fundamentals:** Be ready for questions on core ML/DL/LLM concepts, algorithms, metrics, and best practices.\n",
      "    *   **System Design:** This is where you can shine! Practice ML system design questions, focusing on scalability, reliability, data flow, and infrastructure. Be prepared to discuss how you'd deploy and monitor an LLM application.\n",
      "    *   **Behavioral:** Standard senior engineer questions.\n",
      "4.  **Target Roles:**\n",
      "    *   **ML Engineer:** Often involves productionizing models, building pipelines, MLOps. Your sweet spot.\n",
      "    *   **Applied Scientist (ML/LLM):** More focus on experimenting, researching, and developing models, sometimes less on pure production engineering.\n",
      "    *   **MLOps Engineer:** Specializes in the deployment, monitoring, and infrastructure of ML systems. A natural fit given your background.\n",
      "\n",
      "---\n",
      "\n",
      "### Continuous Learning (Always On)\n",
      "\n",
      "*   **Stay Updated:** The LLM/ML field evolves incredibly fast. Read papers (arXiv), follow prominent researchers/engineers on Twitter/LinkedIn, subscribe to newsletters.\n",
      "*   **Deepen Knowledge:** Explore advanced topics like reinforcement learning, specific fine-tuning techniques, ethics in AI, etc.\n",
      "*   **Experiment:** Try new models, frameworks, and tools as they emerge.\n",
      "\n",
      "---\n",
      "\n",
      "**Key Advice for a Senior Engineer:**\n",
      "\n",
      "*   **Don't forget your roots:** Your Scala/Java experience in building robust, scalable systems is a *huge* asset. Many ML engineers struggle with the \"production\" aspect. You can bridge that gap.\n",
      "*   **Focus on the \"why\":** Understand the intuition behind ML concepts, not just how to use a library.\n",
      "*   **Build, build, build:** Practical projects are the best way to learn and demonstrate your skills.\n",
      "*   **Be patient and persistent:** It's a journey, not a sprint. Celebrate small victories and learn from setbacks.\n",
      "\n",
      "Good luck on this exciting transition!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"You are a LLM principal engineer\"\n",
    "user_prompt = \"\"\"\n",
    "    Create a plan for senior engineer to switch from scala and java to LLM and machine learning development\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt},\n",
    "] # fill this in\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "response = openai.chat.completions.create(model=GEMINI_MODEL, messages=messages)\n",
    "\n",
    "# Step 4: print the result\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af6426db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='9z9ZaeTQIeilqfkP8pCsiQc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is an excellent goal for a Senior Engineer! Your background in Scala and Java, particularly if it involved distributed systems, data processing (e.g., Spark), or high-performance backends, provides a fantastic foundation for tackling the complexities of LLM and ML development.\\n\\nThe key is to leverage your existing software engineering maturity while acquiring new domain-specific knowledge and tools.\\n\\nHere\\'s a comprehensive plan, broken down into phases:\\n\\n---\\n\\n## Plan for a Senior Engineer: Scala/Java to LLM/ML Development\\n\\n**Goal:** Transition into a role focused on LLM and Machine Learning development, leveraging existing Senior Software Engineering skills.\\n\\n**Target Roles:** ML Engineer, Applied Scientist (ML), MLOps Engineer, AI Platform Engineer.\\n\\n---\\n\\n### Phase 0: Self-Assessment & Mindset (Weeks 1-2)\\n\\n1.  **Identify Current Strengths:**\\n    *   **Software Engineering:** Architecture, design patterns, testing, CI/CD, code quality, performance optimization, debugging, distributed systems, concurrency. These are *highly* transferable.\\n    *   **Data Engineering (if applicable):** If you\\'ve worked with data pipelines, Kafka, Spark, data warehousing, this is a huge advantage for ML data preparation and feature engineering.\\n    *   **Problem Solving:** Your senior experience means you can break down complex problems.\\n    *   **Project Management/Leadership:** Ability to lead projects, mentor, and communicate.\\n\\n2.  **Identify Key Gaps:**\\n    *   **Core ML Concepts:** Supervised/Unsupervised Learning, Regression, Classification, Model Evaluation, Feature Engineering, Overfitting, etc.\\n    *   **Deep Learning Fundamentals:** Neural Networks, CNNs, RNNs, Transformers.\\n    *   **LLM Specifics:** Prompt Engineering, RAG (Retrieval Augmented Generation), Fine-tuning, Vector Databases, specific LLM architectures.\\n    *   **Python Ecosystem:** Data manipulation (Pandas, NumPy), ML frameworks (PyTorch/TensorFlow), specific ML/LLM libraries (Hugging Face).\\n    *   **Basic Math & Stats:** Linear algebra, calculus (gradients), probability, statistics.\\n    *   **MLOps:** Tools and practices for deploying, monitoring, and maintaining ML models in production.\\n\\n3.  **Set Realistic Expectations:** This is a significant shift. It will require dedicated study and practice. Expect at least 6-12 months of intensive learning and project work before feeling proficient in a new role.\\n\\n---\\n\\n### Phase 1: Foundational Learning & Tooling (Months 1-3)\\n\\nThe goal here is to build a solid base in Python, essential math, and core ML concepts.\\n\\n1.  **Master Python & its Data Ecosystem:**\\n    *   **Language Fundamentals:** Refresh or learn Python syntax, data structures, OOP.\\n    *   **Essential Libraries:**\\n        *   `NumPy`: Numerical computing.\\n        *   `Pandas`: Data manipulation and analysis (this is *critical* for ML data prep).\\n        *   `Matplotlib`/`Seaborn`: Data visualization.\\n        *   `Scikit-learn`: Classic ML algorithms (start here for basic model understanding).\\n    *   **Practice:** Solve Python challenges, re-implement some simple data structures or algorithms.\\n\\n2.  **Reinforce Essential Math & Statistics:**\\n    *   **Linear Algebra:** Vectors, matrices, dot products, eigenvalues (understand the intuition behind these for neural networks).\\n    *   **Calculus:** Derivatives, gradients (understand how they relate to optimization).\\n    *   **Probability & Statistics:** Basic distributions, hypothesis testing, correlation, variance, bias (crucial for model evaluation and understanding data).\\n    *   **Resources:** Khan Academy, 3Blue1Brown (videos are excellent for intuition), online courses specifically for ML math. *Focus on the intuition and application, not just rote memorization.*\\n\\n3.  **Grasp Core Machine Learning Concepts:**\\n    *   **Key Concepts:** Supervised vs. Unsupervised, Regression vs. Classification, Bias-Variance Tradeoff, Overfitting/Underfitting, Cross-Validation, Feature Engineering, Evaluation Metrics (Accuracy, Precision, Recall, F1, ROC-AUC, RMSE, MAE).\\n    *   **Basic Algorithms:** Linear Regression, Logistic Regression, Decision Trees, Random Forests, SVMs, K-Means.\\n    *   **Resources:**\\n        *   **Andrew Ng\\'s Machine Learning Specialization (Coursera):** A classic and highly recommended starting point.\\n        *   **\"Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow\" by AurÃ©lien GÃ©ron:** Excellent practical guide.\\n\\n---\\n\\n### Phase 2: Deep Dive into Deep Learning & LLMs (Months 4-7)\\n\\nNow, move into the more advanced topics and the specific LLM world.\\n\\n1.  **Deep Learning Fundamentals:**\\n    *   **Neural Networks:** Perceptrons, activation functions, backpropagation (understand the intuition and process).\\n    *   **Architectures:**\\n        *   **CNNs:** Convolutional Neural Networks (for image tasks, good for understanding specialized layers).\\n        *   **RNNs/LSTMs:** Recurrent Neural Networks (for sequence data, understand limitations).\\n        *   **Transformers:** The *most critical* architecture for LLMs. Understand self-attention, multi-head attention, encoder-decoder structure.\\n    *   **Frameworks:** Choose one to start â€“ **PyTorch is often preferred for research and flexibility**, TensorFlow is robust for production.\\n        *   Learn how to build, train, and evaluate simple neural networks.\\n    *   **Resources:**\\n        *   **Deep Learning Specialization by Andrew Ng (Coursera):** Follow-up to his ML course.\\n        *   **\"Deep Learning with Python\" by FranÃ§ois Chollet:** Practical guide using Keras/TensorFlow.\\n        *   **fast.ai course:** Practical, top-down approach to deep learning.\\n\\n2.  **LLM Specifics:**\\n    *   **Hugging Face Ecosystem:** This is the de-facto standard for LLMs. Learn to use:\\n        *   `transformers` library: Load pre-trained models, tokenize, generate text.\\n        *   `datasets` library: Load and prepare data for LLMs.\\n        *   `accelerate` (for distributed training).\\n    *   **Prompt Engineering:** Techniques for crafting effective prompts (few-shot, chain-of-thought, persona prompting).\\n    *   **Vector Databases & Embeddings:** Understand what embeddings are, how to generate them (e.g., using `sentence-transformers`), and how to use vector databases (e.g., Pinecone, Weaviate, ChromaDB, FAISS) for RAG.\\n    *   **Retrieval Augmented Generation (RAG):** The current standard for grounding LLMs with external knowledge. Understand the architecture: indexing, retrieval, generation.\\n    *   **Fine-tuning:** Concepts of PEFT (Parameter Efficient Fine-Tuning) methods like LoRA. Understand when to fine-tune vs. prompt engineer.\\n    *   **Evaluation Metrics:** BLEU, ROUGE, Perplexity for generative tasks. Understand human evaluation.\\n    *   **Resources:**\\n        *   **Hugging Face Course:** Excellent and practical.\\n        *   **Online blogs, papers, and tutorials on RAG, fine-tuning.**\\n        *   **LangChain/LlamaIndex:** Frameworks to build LLM applications.\\n\\n---\\n\\n### Phase 3: Practical Application & Portfolio Building (Months 7-10)\\n\\nThis is where your senior engineering experience truly kicks in. Apply what you\\'ve learned to build projects.\\n\\n1.  **Kaggle Competitions:**\\n    *   Start with beginner-friendly competitions.\\n    *   Focus on understanding data, feature engineering, model selection, and evaluation.\\n    *   Review winning solutions to learn best practices.\\n\\n2.  **Personal Projects (Crucial for demonstrating skills):**\\n    *   **Small ML Projects:** Implement classic algorithms from scratch. Build a simple image classifier or text sentiment analyzer.\\n    *   **LLM-Specific Project 1 (RAG):**\\n        *   Build a Q&A chatbot over a set of your own documents (e.g., your blog posts, documentation).\\n        *   Use `sentence-transformers` for embeddings, a local vector database (like ChromaDB), and a hosted LLM API (OpenAI, Anthropic) or a local open-source model.\\n        *   **Focus on:** Data ingestion, chunking, embedding generation, retrieval accuracy, prompt design, and evaluating response quality.\\n    *   **LLM-Specific Project 2 (Fine-tuning/Agent):**\\n        *   Fine-tune a small open-source model (e.g., from Hugging Face) for a specific task (e.g., summarization of meeting notes, specific style of writing).\\n        *   Or, build a multi-step LLM \"agent\" that can use tools to achieve a goal.\\n    *   **Showcase on GitHub:**\\n        *   Clean code, well-documented, clear `README.md` with instructions and results.\\n        *   Include unit tests, CI/CD where appropriate (leveraging your existing skills!).\\n\\n3.  **Blog/Technical Writing:**\\n    *   Write about your learning journey, specific challenges, or how you solved a problem in your projects. This demonstrates understanding and communication skills.\\n\\n---\\n\\n### Phase 4: MLOps & Productionization (Months 10-12+)\\n\\nThis is where your existing Scala/Java software engineering maturity becomes a massive differentiator. You can build robust, scalable ML systems.\\n\\n1.  **Understand the MLOps Lifecycle:** Data preparation, model training, versioning, deployment, monitoring, re-training.\\n2.  **Tools & Concepts:**\\n    *   **Containerization:** `Docker` (essential for packaging ML applications).\\n    *   **Orchestration:** `Kubernetes` (for deploying and scaling ML services).\\n    *   **ML Metadata/Experiment Tracking:** `MLflow`, `Weights & Biases` (for tracking experiments, models, and parameters).\\n    *   **Data Orchestration:** `Airflow`, `Prefect`, `Dagster` (for scheduling and managing data pipelines).\\n    *   **Model Serving:** `FastAPI` (for building API endpoints for models), `BentoML`, `Seldon Core`, `Triton Inference Server`.\\n    *   **Cloud ML Platforms:** AWS SageMaker, GCP Vertex AI, Azure ML (understand their offerings for training, deployment, and monitoring).\\n    *   **Data Pipelines:** If you have Spark/Kafka experience, focus on how these integrate into ML data ingestion and feature store creation.\\n    *   **Monitoring:** Model drift, data drift, performance metrics.\\n3.  **Leverage your Scala/Java skills:**\\n    *   **Data Engineering:** Your experience with Spark, Kafka, distributed databases is *highly valuable* for building scalable data ingestion and feature engineering pipelines for ML.\\n    *   **Backend Services:** Build robust API gateways, orchestration layers, and data services in Java/Scala that interact with Python-based ML models.\\n    *   **Infrastructure as Code:** Apply your IaC experience to ML infrastructure (Terraform, CloudFormation).\\n    *   **Reliability & Performance:** Design ML systems with resilience, observability, and performance in mind â€“ areas you already excel at.\\n4.  **Project:** Build an end-to-end ML/LLM application, from data ingestion to model deployment and monitoring. For example, deploy your RAG chatbot project as a FastAPI service inside Docker, potentially on Kubernetes.\\n\\n---\\n\\n### Phase 5: Career Transition & Interview Prep (Ongoing)\\n\\n1.  **Update Resume/LinkedIn:**\\n    *   Reframe your experience to highlight transferable skills (distributed systems, data pipelines, software architecture, performance) *and* your new ML/LLM skills.\\n    *   Showcase your projects prominently.\\n2.  **Network:**\\n    *   Connect with ML/LLM professionals on LinkedIn.\\n    *   Attend virtual or local meetups, conferences, and webinars.\\n    *   Informational interviews can provide valuable insights and leads.\\n3.  **Interview Preparation:**\\n    *   **Coding:** Practice Python data structures and algorithms (LeetCode).\\n    *   **ML Fundamentals:** Be ready for questions on core ML/DL/LLM concepts, algorithms, metrics, and best practices.\\n    *   **System Design:** This is where you can shine! Practice ML system design questions, focusing on scalability, reliability, data flow, and infrastructure. Be prepared to discuss how you\\'d deploy and monitor an LLM application.\\n    *   **Behavioral:** Standard senior engineer questions.\\n4.  **Target Roles:**\\n    *   **ML Engineer:** Often involves productionizing models, building pipelines, MLOps. Your sweet spot.\\n    *   **Applied Scientist (ML/LLM):** More focus on experimenting, researching, and developing models, sometimes less on pure production engineering.\\n    *   **MLOps Engineer:** Specializes in the deployment, monitoring, and infrastructure of ML systems. A natural fit given your background.\\n\\n---\\n\\n### Continuous Learning (Always On)\\n\\n*   **Stay Updated:** The LLM/ML field evolves incredibly fast. Read papers (arXiv), follow prominent researchers/engineers on Twitter/LinkedIn, subscribe to newsletters.\\n*   **Deepen Knowledge:** Explore advanced topics like reinforcement learning, specific fine-tuning techniques, ethics in AI, etc.\\n*   **Experiment:** Try new models, frameworks, and tools as they emerge.\\n\\n---\\n\\n**Key Advice for a Senior Engineer:**\\n\\n*   **Don\\'t forget your roots:** Your Scala/Java experience in building robust, scalable systems is a *huge* asset. Many ML engineers struggle with the \"production\" aspect. You can bridge that gap.\\n*   **Focus on the \"why\":** Understand the intuition behind ML concepts, not just how to use a library.\\n*   **Build, build, build:** Practical projects are the best way to learn and demonstrate your skills.\\n*   **Be patient and persistent:** It\\'s a journey, not a sprint. Celebrate small victories and learn from setbacks.\\n\\nGood luck on this exciting transition!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1767456759, model='gemini-2.5-flash', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=3085, prompt_tokens=31, total_tokens=4556, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed9f14-b349-40e9-a42c-b367e77f8bda",
   "metadata": {},
   "source": [
    "## An extra exercise for those who enjoy web scraping\n",
    "\n",
    "You may notice that if you try `display_summary(\"https://openai.com\")` - it doesn't work! That's because OpenAI has a fancy website that uses Javascript. There are many ways around this that some of you might be familiar with. For example, Selenium is a hugely popular framework that runs a browser behind the scenes, renders the page, and allows you to query it. If you have experience with Selenium, Playwright or similar, then feel free to improve the Website class to use them. In the community-contributions folder, you'll find an example Selenium solution from a student (thank you!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeab24dc-5f90-4570-b542-b0585aca3eb6",
   "metadata": {},
   "source": [
    "# Sharing your code\n",
    "\n",
    "I'd love it if you share your code afterwards so I can share it with others! You'll notice that some students have already made changes (including a Selenium implementation) which you will find in the community-contributions folder. If you'd like add your changes to that folder, submit a Pull Request with your new versions in that folder and I'll merge your changes.\n",
    "\n",
    "If you're not an expert with git (and I am not!) then GPT has given some nice instructions on how to submit a Pull Request. It's a bit of an involved process, but once you've done it once it's pretty clear. As a pro-tip: it's best if you clear the outputs of your Jupyter notebooks (Edit >> Clean outputs of all cells, and then Save) for clean notebooks.\n",
    "\n",
    "Here are good instructions courtesy of an AI friend:  \n",
    "https://chatgpt.com/share/677a9cb5-c64c-8012-99e0-e06e88afd293"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4484fcf-8b39-4c3f-9674-37970ed71988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
